q1:
  text: "Does the system process biometric or facial recognition data?"
  high_risk_values: ["yes"]
q2:
  text: "Is the system intended for remote or real‑time biometric identification in public spaces?"
  high_risk_values: ["yes"]
q3:
  text: "Does the system use sensitive personal data (e.g., health, genetic, political, religious)?"
  high_risk_values: ["yes"]
q4:
  text: "Is the system used for predictive profiling or behavior analysis of individuals?"
  high_risk_values: ["yes"]
q5:
  text: "Does the system generate or manipulate audio/video content to mimic individuals (deepfakes)?"
  high_risk_values: ["yes"]
q6:
  text: "Is the system used for automated decision‑making with legal or significant effects (e.g., credit scoring)?"
  high_risk_values: ["yes"]
q7:
  text: "Does the system operate in critical infrastructure sectors (e.g., energy, transport)?"
  high_risk_values: ["yes"]
q8:
  text: "Is the system deployed for law enforcement or public security purposes?"
  high_risk_values: ["yes"]
q9:
  text: "Is the system used in migration, asylum, or border control procedures?"
  high_risk_values: ["yes"]
q10:
  text: "Does the system profile or screen job applicants for recruitment?"
  high_risk_values: ["yes"]
q11:
  text: "Is the system used in healthcare or medical diagnostics?"
  high_risk_values: ["yes"]
q12:
  text: "Does the system infer emotional state or mental health from user data?"
  high_risk_values: ["yes"]
q13:
  text: "Is the system intended to interact with or target children?"
  high_risk_values: ["yes"]
q14:
  text: "Does the system process location tracking or real‑time movement data?"
  high_risk_values: ["yes"]
q15:
  text: "Does the system enable social scoring or reputation scoring of individuals?"
  high_risk_values: ["yes"]
q16:
  text: "Is the system used for remote educational or exam proctoring?"
  high_risk_values: ["yes"]
q17:
  text: "Does the system make automated decisions that cannot be human‑reviewed?"
  high_risk_values: ["yes"]
q18:
  text: "Does the system use training data from non‑EU jurisdictions without compliance checks?"
  high_risk_values: ["yes"]
q19:
  text: "Is the system capable of continuous learning from user interactions?"
  high_risk_values: ["yes"]
q20:
  text: "Does the system lack transparency or explainability features?"
  high_risk_values: ["yes"]
q21:
  text: "Does the system operate without human oversight or fail‑safe measures?"
  high_risk_values: ["yes"]
q22:
  text: "Is the system designed to influence individuals’ behavior or opinions?"
  high_risk_values: ["yes"]
q23:
  text: "Does the system handle data of vulnerable individuals (e.g., disabled)?"
  high_risk_values: ["yes"]
q24:
  text: "Is the system subject to CE marking or conformity assessment under the AI Act?"
  high_risk_values: ["yes"]
q25:
  text: "Does the system lack documented risk management procedures?"
  high_risk_values: ["yes"]
q26:
  text: "Is personal data retention or logging not limited to what is strictly necessary?"
  high_risk_values: ["yes"]
q27:
  text: "Does the system use open‑source or third‑party models without provenance tracking?"
  high_risk_values: ["yes"]
q28:
  text: "Is there no mechanism for individuals to contest or seek redress for automated decisions?"
  high_risk_values: ["yes"]
q29:
  text: "Does the system process data beyond its original purpose without user re‑consent?"
  high_risk_values: ["yes"]
q30:
  text: "Is the system intended for use in high‑stakes financial decision‑making?"
  high_risk_values: ["yes"]
